# -*- coding: utf-8 -*-
"""정량분석

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KC8l0Hyg-0A-M_3sVZErQk-jahR6nkLE

### 파이썬으로 구현하는 정량위험분석 팀웍에 함께 해주셔서 감사합니다. 잘 부탁드리겠습니다

[참가자]
###### 농림축산검역본부 권오규 주무관, kwon.riskanalysis@gmail.com, 010-8448-4861
###### 농림축산검역본부 이해동 연구원, rjadurleegongja07@gmail.com, 010-5062-0147


[지도교수님]
##### 한남대학교 통계학과 권세혁 교수님


#### pert는 !pip install pertdist로 설치하면 구동됩니다

구글 드라이브 연동
"""
"""Third party library 설치 (공유시에는 어떻게 설치해야 하는지.)"""


# Commented out IPython magic to ensure Python compatibility.
# library import
import pandas as pd
import seaborn as sns
import numpy as np
import scipy as sp
from scipy.stats import sem, t, norm
from scipy.special import beta
import matplotlib.pyplot as plt
from pert import PERT
# %matplotlib inline

# 논문 내의 변수 함수 정의

def Hslt_low(N): # 저위험국가의 월별 감염돈의 도축 확률, rvs는 random number 생성을 위한 문법
    result = Proasf.rvs(N)*Hlow.rvs(N)*Tinf.rvs(N)*Hunder.rvs(N)
    return result

def Hslt_med(N): # 중간위험국의 월별 감염돈의 도축 확률
    result = Proasf.rvs(N)*Hmed.rvs(N)*Tinf.rvs(N)*Hunder.rvs(N)
    return result

def Hslt_high(N):
    for a,b,c,d,e in zip(nation_P1['국가명'], nation_P1['population'],nation_P1['평균 감염두수'],nation_P1['발생한 월 수'],nation_P1['유병률평균']): #국가별 유병률 신뢰도 구간 및 평균값 계산(BETA 분포)
        var1 = c*d*e*Tinf.rvs(1)/Hunder.rvs(1)*uni(float(Proslt.rvs(1)),1).rvs(1)+1
        var2 = b*Proslt.rvs(1)-(var1-1)+1
        beta = sp.stats.beta(var1,var2)
    return beta.rvs(N)

def bet(a,b): #베타분포 함수
    beta = sp.stats.beta(a,b)
    return beta

def uni(a,b):  #균등분포 함수
    unidata= sp.stats.uniform(a,b)
    return unidata

#신뢰구간 Beta distribution


def bet_ci(a,b,N, confidence=0.95):
        at = bet(a,b).rvs(N)
        n = len(at)
        m, se = np.mean(at), np.std(at)
        h = se * sp.stats.t._pdf((1+confidence)/2., n-1)

        # plt.xlim(0,1)
        # sns.distplot(at)

        return m-h,m,m+h

# k=int(input('a를 입력하세요'))
# l=int(input('b를 입력하세요'))

# bet_ci(k,l,10000,confidence=.95)

Proasf = PERT(0,.002,.02) #ASF 발생에 따른 사육돼지의 감염 비율
Hmed= PERT(0,.0022,.022) #중간 위험국가에서 ASF 발생가능성
Hlow = PERT(0,.00022,.0022) # 저위험국가에서 ASF 발생가능성 = 중간수준 위험국가의 1/10 위험수준으로 판단
Hunder = PERT(.2,.4,.6) # 보고되지 않는 발생건 비율
Tinf = PERT(3,11,30) # ASF 월별 발생기간
Proslt = PERT(.1,.18,.25) #월별 돈육 생산을 위한 도축두수 비율

# df = pd.read_excel('/content/drive/My Drive/kwon gongja  IRA/asf outbreak_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴
df = pd.read_excel('asf outbreak_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴

# len(df)
china = df['중국']
# china
c_list = []
d_list = []
e_list = []

for a, b in zip(china['a'], china['b']):
    c, d, e = bet_ci(a, b, N=10000, confidence=0.95)
    c_list.append(c)
    d_list.append(d)
    e_list.append(e)

c_d_df = pd.DataFrame({'pre_ci':c_list, 'mean':d_list,'post_ci':e_list}) # c_d_df

china1 = pd.concat([china, c_d_df], axis=1)
china1

# df = pd.read_excel('/content/drive/My Drive/kwon gongja  IRA/asf outbreak_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴
df = pd.read_excel('asf outbreak_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴

nation_P = df['국가별두수']


e_list = [] #빈 리스트 작성하기
f_list = []
g_list = []
k_list = []
var1_list = []
var2_list = []

for a,b in zip(nation_P['s+1'], nation_P['n-s+1']): #국가별 유병률 신뢰도 구간 및 평균값 계산(BETA 분포)
    e,f,g = bet_ci(a, b, N=10000, confidence=0.95)
    e_list.append(e)
    f_list.append(f)
    g_list.append(g)


e_f_df = pd.DataFrame({'하위5%':e_list, '유병률평균':g_list, '상위 5%':f_list}) #데이터프레임 만들기

nation_P1 = pd.concat([nation_P, e_f_df], axis=1) #데이터 프레임 합치기

def Hslt_high(N):
    for a,b,c,d,e in zip(nation_P1['국가명'], nation_P1['population'],nation_P1['평균 감염두수'],nation_P1['발생한 월 수'],nation_P1['유병률평균']): #국가별 유병률 신뢰도 구간 및 평균값 계산(BETA 분포)
        var1 = c*d*e*Tinf.rvs(1)/Hunder.rvs(1)*uni(float(Proslt.rvs(1)),1).rvs(1)+1
        var2 = b*Proslt.rvs(1)-(var1-1)+1
        beta = sp.stats.beta(var1,var2)
    return beta.rvs(N)

"""import data_0420"""

# import_data = pd.read_excel('/content/drive/My Drive/kwon gongja  IRA/import data_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴
import_data = pd.read_excel('import data_0420.xlsx', sheet_name=None)  # None : 모든 시트를 set형식으로 가져옴


total_df = import_data['TOTAL']

val_list = []
gr_list = total_df['등급']
for gr in gr_list:
    n=1000
    if gr == 'L':
        val_list.append(Hslt_low(n))
    elif gr == 'M':
        val_list.append(Hslt_med(n))
    elif gr == 'H':
        val_list.append(Hslt_high(n))

val_df = pd.DataFrame({'unnamed' : val_list})

tot=pd.concat([total_df, val_df], axis=1)
tot

tot=pd.concat([total_df, val_df], axis=1)

incheon_list = []
kimpo_list = []
daegu_list = []
muan_list = []
cheongju_list = []
yangyang_list = []
jeju_list = []

for a,b,c,d,e,f,g,h in zip(tot['인천불합격'], tot['김포불합격'],tot['대구불합격'],tot['무안불합격'],tot['청주불합격'],tot['양양불합격'],tot['제주불합격'],tot['unnamed']):
    a1=1-(1-h)**a
    b1=1-(1-h)**b
    c1=1-(1-h)**c
    d1=1-(1-h)**d
    e1=1-(1-h)**e
    f1=1-(1-h)**f
    g1=1-(1-h)**g
    incheon_list.append(a1)
    kimpo_list.append(b1)
    daegu_list.append(c1)
    muan_list.append(d1)
    cheongju_list.append(e1)
    yangyang_list.append(f1)
    jeju_list.append(g1)

tot_df = pd.DataFrame({'인천최종':incheon_list, '김포최종':kimpo_list, '대구최종':daegu_list,'무안최종':muan_list,'청주최종':cheongju_list,'양양최종':yangyang_list,'제주최종':jeju_list}) #데이터프레임 만들기

totals = pd.concat([tot, tot_df], axis=1) #데이터 프레임 합치기
totals



total_df.columns


# lm_features = ['acceleration', 'cylinders', 'weight', 'displacement']
# for i in enumerate(lm_features): # 인덱스와 같이 작동하는 것
    # row = int(i/2) #처음 인덱스는 0
    # col = i%2 # 컬럼도 처음에 0


# # 시본의 regplot을 이용해 산점도와 선형 회귀 직선을 함께 표현


# sns.regplot(x=feature, y='mpg', data=df_s, ax=axs[row][col])[출처] 20200324 - 파이썬 빅데이터 시각화|작성자 낫싱

"""https://rfriend.tistory.com/275
판다스 피벗 참고 사이트

https://rfriend.tistory.com/256 판다스 concat

https://doorbw.tistory.com/172 판다스 인덱싱(추가, 삭제)

1. PERT함수를 구동하고 마지막에 Hslt_high 값을 작성하였는데, 난수 추출을 해보면 0만을 반환하는 상황입니다. BETA분포의 알파-베타값이 너무 커서 그런것으로 보입니다만, 이런 경우에 알파베타값을 보정하는 방법이 있을지 아니면, 코드에 문제가 있는 것인지 잘 모르겠습니다

2. 논문의 맨 처음에 공식을 두고 있습니다(이항분포같은...) 이 식에 기초해서 위험도를 합산하도록 되어 있는데요. 어떤 식으로 난수값의 확률분포를 합산해야 할지 감이 오지 않습니다. PYMC와 같은 모듈을 사용해야 하는 것인지요.
  **#### : 지수는 아직 지표를 다 입력하지 않아 확정값을 입력하였고, 난수 1000개에 따른 평균값으로 그래프를 작성해보았습니다. LIST를 오름차순으로 정리하여 그리면 되는 것인지 잘 모르겠습니다**

3. pert분포를 만들어서 uniform함수의 1개의 변수로 사용하는 방법은?
"""
